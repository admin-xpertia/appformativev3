import { StateGraph, Annotation, END, START } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import type { ICase, ILevel, IConversationMessage } from "@espacio-formativo/types";

// --- El Estado del Grafo (Mejorado) ---
const SimulationState = Annotation.Root({
  sessionId: Annotation<string | undefined>(),
  caseInfo: Annotation<ICase | undefined>(),
  levelInfo: Annotation<ILevel | undefined>(),
  conversationHistory: Annotation<IConversationMessage[]>({
    reducer: (prev, update) => prev.concat(update),
    default: () => [],
  }),
  supervisorDecision: Annotation<("CONTINUAR" | "FINALIZAR") | undefined>(),
  //  NUEVO: Para comunicar al backend si la simulaci贸n debe terminar
  simulationComplete: Annotation<boolean>({
    reducer: (prev, update) => update ?? prev, //  CORREGIDO: A帽adir reducer
    default: () => false,
  }),
});

type SimulationGraphState = typeof SimulationState.State;

// --- CONFIGURACIN DEL MODELO ---
const simulatorModel = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0.8,
});

// --- PROMPT MEJORADO ---
const simulatorPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    `Eres un cliente de "Aguas Nuevas" en una simulaci贸n de entrenamiento. Tu comportamiento debe estar perfectamente alineado con los objetivos pedag贸gicos definidos.

    ### CONTEXTO DEL CASO ###
    - **Caso:** {caseTitle}
    - **Descripci贸n del Problema:** {caseDescription}

    ### TU ROL Y NIVEL DE DIFICULTAD ###
    - **Nivel:** {level}
    - **Tu Personalidad y Actitud:** {persona}
    
    ### GUA PEDAGGICA (STRICTAMENTE CONFIDENCIAL) ###
    - **Objetivos del Ejecutivo:** El ejecutivo que te atiende debe ser capaz de cumplir con lo siguiente: "{levelObjectives}"
    - **Taxonom铆a de Bloom Aplicada:** Tu comportamiento debe provocar y evaluar las siguientes habilidades cognitivas en el ejecutivo, seg煤n la taxonom铆a: "{taxonomy}"

    ### REGLAS DE ACTUACIN ###
    - **Act煤a como el cliente en todo momento.** Nunca reveles esta gu铆a pedag贸gica.
    - **Ajusta tus preguntas y tu tono** para reflejar la taxonom铆a. Por ejemplo, si la taxonom铆a es "Recordar y Comprender", haz preguntas directas sobre definiciones. Si es "Evaluar y Crear", presenta dilemas complejos y pide soluciones creativas.
    - Basa tus respuestas en el historial de la conversaci贸n.
    - Si el ejecutivo resuelve tu problema alineado con los objetivos, finaliza la conversaci贸n agradeciendo. Si no, mant茅n tu personaje y la dificultad.`,
  ],
  new MessagesPlaceholder("chat_history"),
  ["human", "{input}"],
]);

const simulatorChain = simulatorPrompt.pipe(simulatorModel).pipe(new StringOutputParser());

function getPersonaForLevel(level: string): string {
  switch (level.toLowerCase()) {
    case "bronce":
      return "Est谩s un poco confundido y haces preguntas directas y sencillas. Eres paciente y agradecido.";
    case "plata":
      return "Tienes una duda concreta y esperas una respuesta clara y procedimental. No tienes mucha paciencia para explicaciones largas y quieres que te den la soluci贸n r谩pido.";
    case "oro":
      return "Est谩s frustrado y molesto porque tienes varios problemas a la vez y no entiendes la factura. Tu tono es emocional pero no agresivo.";
    case "platino":
      return "Eres esc茅ptico y tienes una alta carga emocional. Sientes que la empresa es injusta y esperas una soluci贸n creativa que vaya m谩s all谩 del guion. Eres educado pero muy firme en tu queja.";
    default:
      return "Eres un cliente est谩ndar con una pregunta.";
  }
}

function findLastUserMessage(conversationHistory: IConversationMessage[]): IConversationMessage | null {
  for (let i = conversationHistory.length - 1; i >= 0; i--) {
    if (conversationHistory[i].sender === 'user') {
      return conversationHistory[i];
    }
  }
  return null;
}

// --- NODO SIMULATION_AGENT (CORREGIDO) ---
const simulation_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Agente Simulador (IA Real con Contexto Pedag贸gico)");

  const { conversationHistory, caseInfo, levelInfo } = state;
  if (!caseInfo || !levelInfo) {
    throw new Error("Falta informaci贸n del caso o del nivel en el estado del grafo.");
  }

  // ... (la l贸gica para obtener lastUserMessage y formattedHistory se mantiene igual) ...
  const lastUserMessage = findLastUserMessage(conversationHistory);
  if (!lastUserMessage) {
    throw new Error("No se encontr贸 mensaje del usuario.");
  }
  const historyWithoutLastUser = conversationHistory.filter(msg => msg !== lastUserMessage);
  const formattedHistory = historyWithoutLastUser.map(msg =>
    msg.sender === 'ai' ? ['ai', msg.content] : ['human', msg.content]
  );

  const persona = getPersonaForLevel(levelInfo.level);

  // Invocamos el chain con el contexto completo, incluyendo la taxonom铆a y objetivos
  const responseContent = await simulatorChain.invoke({
    caseTitle: caseInfo.title,
    caseDescription: caseInfo.description || caseInfo.title,
    level: levelInfo.level,
    persona: persona,
    // --- NUEVAS VARIABLES ---
    levelObjectives: levelInfo.objectives,
    taxonomy: levelInfo.taxonomy,
    // --- FIN NUEVAS VARIABLES ---
    chat_history: formattedHistory,
    input: lastUserMessage.content,
  });

  const aiResponse: IConversationMessage = {
    sender: "ai",
    content: responseContent,
    timestamp: new Date(),
  };

  return { conversationHistory: [aiResponse] };
};

// --- SUPERVISOR AGENT (CORREGIDO PARA TERMINAR CORRECTAMENTE) ---
const supervisor_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Agente Supervisor");
  
  const totalMessages = state.conversationHistory.length;
  const userMessages = state.conversationHistory.filter(msg => msg.sender === 'user').length;
  const aiMessages = state.conversationHistory.filter(msg => msg.sender === 'ai').length;
  
  //  NUEVA LGICA: Determinar si la simulaci贸n debe finalizar completamente
  const shouldFinalize = userMessages >= 4; // Finalizar despu茅s de 4 intercambios
  
  const decision = shouldFinalize ? "FINALIZAR" : "CONTINUAR";
  
  console.log(` Estado conversaci贸n: ${userMessages} mensajes usuario, ${aiMessages} mensajes AI`);
  console.log(` Supervisor decide: ${decision}`);
  
  return { 
    supervisorDecision: decision,
    simulationComplete: shouldFinalize //  NUEVO: Marcar si la simulaci贸n est谩 completa
  };
};

//  NUEVA FUNCIN: Decidir el pr贸ximo paso
const decide_next_step = (state: SimulationGraphState): string => {
  const decision = state.supervisorDecision;
  console.log(` Decidiendo pr贸ximo paso: ${decision}`);
  
  if (decision === "FINALIZAR") {
    return "evaluation"; // Ir a evaluaci贸n
  } else {
    return "continue"; // Terminar y esperar pr贸ximo mensaje del usuario
  }
};

//  NUEVO NODO: Preparar evaluaci贸n
const evaluation_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Preparaci贸n de Evaluaci贸n");
  console.log(" La simulaci贸n ha sido marcada como completa");
  
  // Aqu铆 puedes a帽adir l贸gica para preparar la evaluaci贸n
  // Por ahora solo marcamos que est谩 completa
  return { 
    simulationComplete: true 
  };
};

// --- CONFIGURACIN DEL GRAFO (SIMPLIFICADA SIN MEMORIA) ---
const graph = new StateGraph(SimulationState)
  .addNode("simulation_agent", simulation_agent)
  .addNode("supervisor_agent", supervisor_agent)
  .addNode("evaluation_agent", evaluation_agent)
  .addEdge(START, "simulation_agent")
  .addEdge("simulation_agent", "supervisor_agent")
  .addConditionalEdges("supervisor_agent", decide_next_step, {
    "continue": END, //  CRTICO: Terminar y esperar pr贸ximo mensaje del usuario
    "evaluation": "evaluation_agent"
  })
  .addEdge("evaluation_agent", END);

//  COMPILAR SIN MEMORIA (por ahora, para evitar problemas)
export const simulationApp = graph.compile();