import { StateGraph, Annotation, END, START } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import type { ICase, ILevel, IConversationMessage } from "@espacio-formativo/types";

// --- El Estado del Grafo (Mejorado) ---
const SimulationState = Annotation.Root({
  sessionId: Annotation<string | undefined>(),
  caseInfo: Annotation<ICase | undefined>(),
  levelInfo: Annotation<ILevel | undefined>(),
  conversationHistory: Annotation<IConversationMessage[]>({
    reducer: (prev, update) => prev.concat(update),
    default: () => [],
  }),
  supervisorDecision: Annotation<("CONTINUAR" | "FINALIZAR") | undefined>(),
  // üî• NUEVO: Para comunicar al backend si la simulaci√≥n debe terminar
  simulationComplete: Annotation<boolean>({
    reducer: (prev, update) => update ?? prev, // üîß CORREGIDO: A√±adir reducer
    default: () => false,
  }),
});

type SimulationGraphState = typeof SimulationState.State;

// --- CONFIGURACI√ìN DEL MODELO ---
const simulatorModel = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0.8,
});

// --- PROMPT MEJORADO ---
const simulatorPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    `Eres un cliente de "Aguas Nuevas", una empresa de servicios sanitarios. Tu rol es actuar de forma realista en una simulaci√≥n de atenci√≥n al cliente.

    ### CONTEXTO DE LA SIMULACI√ìN ###
    - **Tu Problema (El Caso):** {caseTitle}
    - **Descripci√≥n del Caso:** {caseDescription}
    - **Nivel de Dificultad:** {level}
    - **Tu Personalidad y Actitud:** {persona}

    ### REGLAS DE ACTUACI√ìN ###
    - Responde **√∫nicamente como el cliente**. Nunca reveles que eres una IA.
    - Basa tus respuestas en el historial de la conversaci√≥n. No repitas informaci√≥n que ya te han dado.
    - Mant√©n tu personalidad asignada. Si eres un cliente frustrado, tus respuestas deben reflejarlo.
    - Tu objetivo es ver si el ejecutivo resuelve tu problema. No le des la soluci√≥n f√°cilmente. Haz las preguntas que un cliente real har√≠a.
    - Si el ejecutivo resuelve tu problema de forma clara y emp√°tica, puedes dar por terminada la conversaci√≥n con un agradecimiento.
    - Responde de manera NATURAL y √öNICA - evita repetir el mismo saludo o pregunta.`,
  ],
  new MessagesPlaceholder("chat_history"),
  ["human", "{input}"],
]);

const simulatorChain = simulatorPrompt.pipe(simulatorModel).pipe(new StringOutputParser());

function getPersonaForLevel(level: string): string {
  switch (level.toLowerCase()) {
    case "bronce":
      return "Est√°s un poco confundido y haces preguntas directas y sencillas. Eres paciente y agradecido.";
    case "plata":
      return "Tienes una duda concreta y esperas una respuesta clara y procedimental. No tienes mucha paciencia para explicaciones largas y quieres que te den la soluci√≥n r√°pido.";
    case "oro":
      return "Est√°s frustrado y molesto porque tienes varios problemas a la vez y no entiendes la factura. Tu tono es emocional pero no agresivo.";
    case "platino":
      return "Eres esc√©ptico y tienes una alta carga emocional. Sientes que la empresa es injusta y esperas una soluci√≥n creativa que vaya m√°s all√° del guion. Eres educado pero muy firme en tu queja.";
    default:
      return "Eres un cliente est√°ndar con una pregunta.";
  }
}

function findLastUserMessage(conversationHistory: IConversationMessage[]): IConversationMessage | null {
  for (let i = conversationHistory.length - 1; i >= 0; i--) {
    if (conversationHistory[i].sender === 'user') {
      return conversationHistory[i];
    }
  }
  return null;
}

// --- NODO SIMULATION_AGENT (CORREGIDO) ---
const simulation_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Agente Simulador (IA Real)");

  const { conversationHistory, caseInfo, levelInfo } = state;
  if (!caseInfo || !levelInfo) {
    throw new Error("Falta informaci√≥n del caso o del nivel en el estado del grafo.");
  }

  const lastUserMessage = findLastUserMessage(conversationHistory);
  
  if (!lastUserMessage) {
    throw new Error("No se encontr√≥ ning√∫n mensaje del usuario en el historial de conversaci√≥n.");
  }

  console.log(`üîç √öltimo mensaje del usuario: "${lastUserMessage.content.substring(0, 50)}..."`);

  // üî• MEJORADO: Construir historial SIN el √∫ltimo mensaje del usuario
  const historyWithoutLastUser = conversationHistory.filter(msg => msg !== lastUserMessage);
  const formattedHistory = historyWithoutLastUser.map(msg =>
    msg.sender === 'ai' ? ['ai', msg.content] : ['human', msg.content]
  );

  const persona = getPersonaForLevel(levelInfo.level);

  try {
    const responseContent = await simulatorChain.invoke({
      caseTitle: caseInfo.title,
      caseDescription: caseInfo.description || caseInfo.title,
      level: levelInfo.level,
      persona: persona,
      chat_history: formattedHistory,
      input: lastUserMessage.content,
    });

    const aiResponse: IConversationMessage = {
      sender: "ai",
      content: responseContent,
      timestamp: new Date(),
    };

    console.log(`ü§ñ Respuesta generada: "${responseContent.substring(0, 100)}..."`);

    return { conversationHistory: [aiResponse] };

  } catch (error) {
    console.error("‚ùå Error en el Agente Simulador:", error);
    throw error;
  }
};

// --- SUPERVISOR AGENT (CORREGIDO PARA TERMINAR CORRECTAMENTE) ---
const supervisor_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Agente Supervisor");
  
  const totalMessages = state.conversationHistory.length;
  const userMessages = state.conversationHistory.filter(msg => msg.sender === 'user').length;
  const aiMessages = state.conversationHistory.filter(msg => msg.sender === 'ai').length;
  
  // üî• NUEVA L√ìGICA: Determinar si la simulaci√≥n debe finalizar completamente
  const shouldFinalize = userMessages >= 4; // Finalizar despu√©s de 4 intercambios
  
  const decision = shouldFinalize ? "FINALIZAR" : "CONTINUAR";
  
  console.log(`üìä Estado conversaci√≥n: ${userMessages} mensajes usuario, ${aiMessages} mensajes AI`);
  console.log(`üéØ Supervisor decide: ${decision}`);
  
  return { 
    supervisorDecision: decision,
    simulationComplete: shouldFinalize // üî• NUEVO: Marcar si la simulaci√≥n est√° completa
  };
};

// üî• NUEVA FUNCI√ìN: Decidir el pr√≥ximo paso
const decide_next_step = (state: SimulationGraphState): string => {
  const decision = state.supervisorDecision;
  console.log(`ü§î Decidiendo pr√≥ximo paso: ${decision}`);
  
  if (decision === "FINALIZAR") {
    return "evaluation"; // Ir a evaluaci√≥n
  } else {
    return "continue"; // Terminar y esperar pr√≥ximo mensaje del usuario
  }
};

// üî• NUEVO NODO: Preparar evaluaci√≥n
const evaluation_agent = async (state: SimulationGraphState): Promise<Partial<SimulationGraphState>> => {
  console.log("-> Entrando al nodo: Preparaci√≥n de Evaluaci√≥n");
  console.log("üéØ La simulaci√≥n ha sido marcada como completa");
  
  // Aqu√≠ puedes a√±adir l√≥gica para preparar la evaluaci√≥n
  // Por ahora solo marcamos que est√° completa
  return { 
    simulationComplete: true 
  };
};

// --- CONFIGURACI√ìN DEL GRAFO (SIMPLIFICADA SIN MEMORIA) ---
const graph = new StateGraph(SimulationState)
  .addNode("simulation_agent", simulation_agent)
  .addNode("supervisor_agent", supervisor_agent)
  .addNode("evaluation_agent", evaluation_agent)
  .addEdge(START, "simulation_agent")
  .addEdge("simulation_agent", "supervisor_agent")
  .addConditionalEdges("supervisor_agent", decide_next_step, {
    "continue": END, // üî• CR√çTICO: Terminar y esperar pr√≥ximo mensaje del usuario
    "evaluation": "evaluation_agent"
  })
  .addEdge("evaluation_agent", END);

// üî• COMPILAR SIN MEMORIA (por ahora, para evitar problemas)
export const simulationApp = graph.compile();